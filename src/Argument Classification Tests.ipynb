{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df476e4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "from allennlp.predictors.predictor import Predictor\n",
    "import allennlp_models.tagging\n",
    "\n",
    "predictor_bert = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/structured-prediction-srl-bert.2020.12.15.tar.gz\")\n",
    "\n",
    "predictor_bilstm = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/openie-model.2020.03.26.tar.gz\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4e351c",
   "metadata": {},
   "source": [
    "### INV: Sentences with em dash phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6cd07df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'original': 'She sang the song in front of a large audience.', 'em_dash': 'She sang the song—beautifully, powerfully, and passionately—in front of a large audience.'}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "with open('data/argument_identification_em_dash_inv_v2.json', 'r') as infile:\n",
    "    sentences = json.loads(infile.read())\n",
    "print(sentences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d6bb79c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(BERT) Argument Classification INV to em dash phrases: 24.0\n",
      "(BiLSTM) Argument Classification INV to em dash phrases: 90.0\n"
     ]
    }
   ],
   "source": [
    "def arg_ident_em_dash_inv(predictor, sentences):\n",
    "    # Initialize an empty list for storing failure cases\n",
    "    failures = []\n",
    "\n",
    "    # Loop through each sentence in the input sentences\n",
    "    for sentence in sentences:\n",
    "        # Get the original and em-dash versions of the sentence\n",
    "        original = sentence['original']\n",
    "        dashed = sentence['em_dash']\n",
    "        \n",
    "        # Use the predictor to make predictions for both sentence versions\n",
    "        original_pred = predictor.predict(original)\n",
    "        dashed_pred = predictor.predict(dashed)\n",
    "        \n",
    "        # Find the indices of em-dashes in the dashed_pred\n",
    "        em_index1 = dashed_pred['words'].index('—')\n",
    "        em_index2 = dashed_pred['words'].index('—', em_index1+1)\n",
    "\n",
    "        # Extract the arguments for each predicate from the original prediction\n",
    "        original_arguments = {}\n",
    "        for predicate in original_pred['verbs']:\n",
    "            verb = predicate['verb']\n",
    "            tags = predicate['tags']\n",
    "            original_arguments[verb] = tags\n",
    "        \n",
    "        # Extract the arguments for each predicate from the dashed prediction, excluding the em-dash\n",
    "        dashed_arguments = {}\n",
    "        for predicate in dashed_pred['verbs']:\n",
    "            verb = predicate['verb']\n",
    "            tags = predicate['tags']\n",
    "            dashed_arguments[verb] = tags[:em_index1] + tags[em_index2+1:]\n",
    "        \n",
    "        # Initialize a variable to track if the current instance failed\n",
    "        failure = 0\n",
    "\n",
    "        # Compare the original and dashed arguments for consistency\n",
    "        for verb in original_arguments:\n",
    "            if verb not in dashed_arguments:\n",
    "                failure = 1\n",
    "            else:\n",
    "                for expected, predicted in zip(original_arguments[verb], dashed_arguments[verb]):\n",
    "                    # If there is a mismatch in the classification of arguments, mark it as a failure\n",
    "                    if expected != predicted:\n",
    "                        failure = 1\n",
    "\n",
    "        # Append the failure status to the list of failures\n",
    "        failures.append(failure)\n",
    "\n",
    "    # Calculate and return the failure rate\n",
    "    return(sum(failures) / len(failures))\n",
    "\n",
    "print(\"(BERT) Argument Classification INV to em dash phrases:\", 100 * arg_ident_em_dash_inv(predictor_bert, sentences))\n",
    "print(\"(BiLSTM) Argument Classification INV to em dash phrases:\", 100 * arg_ident_em_dash_inv(predictor_bilstm, sentences))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "allenNLP",
   "language": "python",
   "name": "allennlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
